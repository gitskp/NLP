{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Text: Moby Dick by Herman Melville 1851>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brown Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the Brown Corpus\n",
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total categories: 15\n"
     ]
    }
   ],
   "source": [
    "print(\"Total categories:\",len(brown.categories()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adventure', 'belles_lettres', 'editorial', 'fiction', 'government', 'hobbies', 'humor', 'learned', 'lore', 'mystery', 'news', 'religion', 'reviews', 'romance', 'science_fiction']\n"
     ]
    }
   ],
   "source": [
    "print(brown.categories())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['There', 'were', 'thirty-eight', 'patients', 'on', 'the', 'bus', 'the', 'morning', 'I', 'left', 'for', 'Hanover', ',', 'most', 'of', 'them', 'disturbed', 'and', 'hallucinating', '.'], ['An', 'interne', ',', 'a', 'nurse', 'and', 'two', 'attendants', 'were', 'in', 'charge', 'of', 'us', '.'], ...]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenized sentences\n",
    "brown.sents(categories='mystery')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('There', 'EX'), ('were', 'BED'), ('thirty-eight', 'CD'), ('patients', 'NNS'), ('on', 'IN'), ('the', 'AT'), ('bus', 'NN'), ('the', 'AT'), ('morning', 'NN'), ('I', 'PPSS'), ('left', 'VBD'), ('for', 'IN'), ('Hanover', 'NP'), (',', ','), ('most', 'AP'), ('of', 'IN'), ('them', 'PPO'), ('disturbed', 'VBN'), ('and', 'CC'), ('hallucinating', 'VBG'), ('.', '.')], [('An', 'AT'), ('interne', 'NN'), (',', ','), ('a', 'AT'), ('nurse', 'NN'), ('and', 'CC'), ('two', 'CD'), ('attendants', 'NNS'), ('were', 'BED'), ('in', 'IN'), ('charge', 'NN'), ('of', 'IN'), ('us', 'PPO'), ('.', '.')], ...]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# POS tagged sentences\n",
    "brown.tagged_sents(categories='mystery')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['There were thirty-eight patients on the bus the morning I left for Hanover , most of them disturbed and hallucinating .', 'An interne , a nurse and two attendants were in charge of us .', \"I felt lonely and depressed as I stared out the bus window at Chicago's grim , dirty West Side .\", 'It seemed incredible , as I listened to the monotonous drone of voices and smelled the fetid odors coming from the patients , that technically I was a ward of the state of Illinois , going to a hospital for the mentally ill .', 'I suddenly thought of Mary Jane Brennan , the way her pretty eyes could flash with anger , her quiet competence , the gentleness and sweetness that lay just beneath the surface of her defenses .']\n"
     ]
    }
   ],
   "source": [
    "# get sentences in natural form\n",
    "sentences = brown.sents(categories='mystery')\n",
    "sentences= [' '.join(sentence_token) for sentence_token in sentences]\n",
    "print(sentences[0:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get tagged words\n",
    "tagged_words= brown.tagged_words(categories='mystery')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get nouns from tagged words\n",
    "nouns = [(word, tag) for word, tag in tagged_words if any(noun_tag in tag for noun_tag in ['NP', 'NN'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('patients', 'NNS'), ('bus', 'NN'), ('morning', 'NN'), ('Hanover', 'NP'), ('interne', 'NN'), ('nurse', 'NN'), ('attendants', 'NNS'), ('charge', 'NN'), ('bus', 'NN'), ('window', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "print( nouns[0:10]) # prints the first 10 nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build frequency distribution for nouns\n",
    "import nltk\n",
    "nouns_freq = nltk.FreqDist([word for word, tag in nouns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('man', 106), ('time', 82), ('door', 80), ('car', 69), ('room', 65), ('Mr.', 63), ('way', 61), ('office', 50), ('eyes', 48), ('hand', 46)]\n"
     ]
    }
   ],
   "source": [
    "# print top 10 occuring nouns\n",
    "print(nouns_freq.most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reuters corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the reuters corpus\n",
    "from nltk.corpus import reuters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acq', 'alum', 'barley', 'bop', 'carcass', 'castor-oil', 'cocoa', 'coconut', 'coconut-oil', 'coffee', 'copper', 'copra-cake', 'corn', 'cotton', 'cotton-oil', 'cpi', 'cpu', 'crude', 'dfl', 'dlr', 'dmk', 'earn', 'fuel', 'gas', 'gnp', 'gold', 'grain', 'groundnut', 'groundnut-oil', 'heat', 'hog', 'housing', 'income', 'instal-debt', 'interest', 'ipi', 'iron-steel', 'jet', 'jobs', 'l-cattle', 'lead', 'lei', 'lin-oil', 'livestock', 'lumber', 'meal-feed', 'money-fx', 'money-supply', 'naphtha', 'nat-gas', 'nickel', 'nkr', 'nzdlr', 'oat', 'oilseed', 'orange', 'palladium', 'palm-oil', 'palmkernel', 'pet-chem', 'platinum', 'potato', 'propane', 'rand', 'rape-oil', 'rapeseed', 'reserves', 'retail', 'rice', 'rubber', 'rye', 'ship', 'silver', 'sorghum', 'soy-meal', 'soy-oil', 'soybean', 'strategic-metal', 'sugar', 'sun-meal', 'sun-oil', 'sunseed', 'tea', 'tin', 'trade', 'veg-oil', 'wheat', 'wpi', 'yen', 'zinc']\n"
     ]
    }
   ],
   "source": [
    "# categories of reuters corpus\n",
    "print(reuters.categories())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n"
     ]
    }
   ],
   "source": [
    "# len of reuters corpus\n",
    "print(len(reuters.categories()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get sentences in housing and income categories\n",
    "sentences = reuters.sents(categories=['housing','income'])\n",
    "sentences = [' '.join(sentence_token) for sentence_token in sentences]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"YUGOSLAV ECONOMY WORSENED IN 1986 , BANK DATA SHOWS National Bank economic data for 1986 shows that Yugoslavia ' s trade deficit grew , the inflation rate rose , wages were sharply higher , the money supply expanded and the value of the dinar fell .\", 'The trade deficit for 1986 was 2 . 012 billion dlrs , 25 . 7 pct higher than in 1985 .', 'The trend continued in the first three months of this year as exports dropped by 17 . 8 pct , in hard currency terms , to 2 . 124 billion dlrs .', 'Yugoslavia this year started quoting trade figures in dinars based on current exchange rates , instead of dollars based on a fixed exchange rate of 264 . 53 dinars per dollar .', \"Yugoslavia ' s balance of payments surplus with the convertible currency area fell to 245 mln dlrs in 1986 from 344 mln in 1985 .\"]\n"
     ]
    }
   ],
   "source": [
    "# prints the first 5 sentences\n",
    "print(sentences[0:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test/16118', 'test/18534', 'test/18540', 'test/18664', 'test/18665', 'test/18672', 'test/18911', 'training/10602', 'training/10604', 'training/2618', 'training/7005', 'training/7006', 'training/7015', 'training/7036', 'training/7098', 'training/7099']\n"
     ]
    }
   ],
   "source": [
    "#  fileid based access\n",
    "print(reuters.fileids(categories=['hoosing','income']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['YUGOSLAV', 'ECONOMY', 'WORSENED', 'IN', '1986', ',', 'BANK', 'DATA', 'SHOWS', 'National', 'Bank', 'economic', 'data', 'for', '1986', 'shows', 'that', 'Yugoslavia', \"'\", 's', 'trade', 'deficit', 'grew', ',', 'the', 'inflation', 'rate', 'rose', ',', 'wages', 'were', 'sharply', 'higher', ',', 'the', 'money', 'supply', 'expanded', 'and', 'the', 'value', 'of', 'the', 'dinar', 'fell', '.'], ['The', 'trade', 'deficit', 'for', '1986', 'was', '2', '.', '012', 'billion', 'dlrs', ',', '25', '.', '7', 'pct', 'higher', 'than', 'in', '1985', '.'], ...]\n"
     ]
    }
   ],
   "source": [
    "print(reuters.sents(fileids=['test/16118','test/18534']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing the WordNet Corpus\n",
    "\n",
    "<font size=2>The WordNet corpus is perhaps one of the most used corpora out there because it consists of a vast corpus of words and semantically linked synsets for each word. We will explore some of the basic features of the WordNet Corpus here, including synsets and methods of accessing the corpus data.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the Wordnet Corpus\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = 'hike' # taking hike as our word of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('hike.n.01'), Synset('rise.n.09'), Synset('raise.n.01'), Synset('hike.v.01'), Synset('hike.v.02')]\n"
     ]
    }
   ],
   "source": [
    "# get word synsets\n",
    "word_synsets = wn.synsets(word)\n",
    "print( word_synsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset Name: hike.n.01\n",
      "POS Tag: n\n",
      "Definition: a long walk usually for exercise or pleasure\n",
      "Examples: ['she enjoys a hike in her spare time']\n",
      "**************\n",
      "Synset Name: rise.n.09\n",
      "POS Tag: n\n",
      "Definition: an increase in cost\n",
      "Examples: ['they asked for a 10% rise in rates']\n",
      "**************\n",
      "Synset Name: raise.n.01\n",
      "POS Tag: n\n",
      "Definition: the amount a salary is increased\n",
      "Examples: ['he got a 3% raise', 'he got a wage hike']\n",
      "**************\n",
      "Synset Name: hike.v.01\n",
      "POS Tag: v\n",
      "Definition: increase\n",
      "Examples: ['The landlord hiked up the rents']\n",
      "**************\n",
      "Synset Name: hike.v.02\n",
      "POS Tag: v\n",
      "Definition: walk a long way, as for pleasure or physical exercise\n",
      "Examples: ['We were hiking in Colorado', 'hike the Rockies']\n",
      "**************\n"
     ]
    }
   ],
   "source": [
    "# get details for each synonym in synset\n",
    "for synset in word_synsets:\n",
    "    print( 'Synset Name:', synset.name())\n",
    "    print('POS Tag:', synset.pos())\n",
    "    print ('Definition:', synset.definition())\n",
    "    print( 'Examples:', synset.examples())\n",
    "    print(\"**************\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application of Natural Language Processing(NLP)\n",
    "- **Machine Translation**\n",
    "    - Machine translation is perhaps one of the most coveted and sought-after applications\n",
    "for NLP. It is defined as the technique that helps in providing syntactic, grammatical,\n",
    "and semantically correct translation between any two pair of languages. It was perhaps\n",
    "the first major area of research and development in NLP. On a simple level, machine\n",
    "translation is the translation of natural language carried out by a machine. By default, the\n",
    "basic building blocks for the machine translation process involve simple substitution of\n",
    "words from one language to another, but in that case we ignore things like grammar and\n",
    "phrasal structure consistency. Hence, more sophisticated techniques have evolved over a\n",
    "period of time, including combining large resources of text corpora along with statistical\n",
    "and linguistic techniques. One of the most popular machine translation systems is Google\n",
    "Translate. Figure 1-19 shows a successful machine translation operation executed by\n",
    "Google Translate for the sentence What is the fare to the airport? from English to Italian.\n",
    "![](http://www.k-international.com/wp-content/uploads/2013/12/Google-Translate.jpg)\n",
    "- **Speech Recognition Systems**\n",
    "    - This is perhaps the most difficult application for NLP. Perhaps the most difficult test of\n",
    "intelligence in artificial intelligence systems is the Turing Test. This test is defined as a\n",
    "test of intelligence for a computer. A question is posed to a computer and a human, and\n",
    "the test is passed if it is impossible to say which of the answers given was given by the\n",
    "human. Over time, a lot of progress has been made in this area by using techniques like\n",
    "speech synthesis, analysis, syntactic parsing, and contextual reasoning. But one chief\n",
    "limitation for speech recognition systems still remains: They are very domain specific and\n",
    "will not work if the user strays even a little bit from the expected scripted inputs needed\n",
    "by the system. Speech-recognition systems are now found in many places, from desktop\n",
    "computers to mobile phones to virtual assistance systems.\n",
    "- **Question Answering Systems**\n",
    "    - Question Answering Systems (QAS) are built upon the principle of Question Answering,\n",
    "based on using techniques from NLP and information retrieval (IR). QAS is primarily\n",
    "concerned with building robust and scalable systems that provide answers to questions\n",
    "given by users in natural language form. Imagine being in a foreign country, asking a\n",
    "question to your personalized assistant in your phone in pure natural language, and\n",
    "getting a similar response from it. This is the ideal state toward which researchers and\n",
    "technologists are working. Some success in this field has been achieved with personalized\n",
    "assistants like Siri and Cortana, but their scope is still limited because they understand\n",
    "only a subset of key clauses and phrases in the entire human natural language. To build a successful QAS, you need a huge knowledgebase consisting of data about\n",
    "various domains. Efficient querying systems into this knowledgebase would be leveraged\n",
    "by the QAS to provide answers to questions in natural language form. Creating and\n",
    "maintaining a queryable vast knowledgebase is extremely difficult—hence, you find the\n",
    "rise of QAS in niche domains like food, healthcare, e-commerce, and so on. Chatbots are\n",
    "one emerging trend that makes extensive use of QAS.\n",
    "- **Contextual Recognition and Resolution**\n",
    "    - This covers a wide area in understanding natural language and includes both syntactic\n",
    "and semantic-based reasoning. Word sense disambiguation is a popular application,\n",
    "where we want to find out the contextual sense of a word in a given sentence. Consider\n",
    "the word book . It can mean an object containing knowledge and information when used\n",
    "as a noun, and it can also mean to reserve a seat or a table when used as a verb. Detecting\n",
    "these differences in sentences based on context is the main premise of word sense\n",
    "disambiguation—a daunting task covered in Chapter 7 .\n",
    "Coreference resolution is another problem in linguistics NLP is trying to address. By\n",
    "definition, coreference is said to occur when two or more terms or expressions in a body\n",
    "of text refer to the same entity. Then they are said to have the same referent . Consider\n",
    "John just told me that he is going to the exam hall . In this sentence, the pronoun he has the\n",
    "referent John . Resolving such pronouns is a part of coreference resolution, and it becomes\n",
    "challenging once we have multiple referents in a body of text. For example, John just talked\n",
    "with Jim. He told me we have a surprise test tomorrow . In this body of text, the pronoun he\n",
    "could refer to either John or Jim , thus making pinpointing the exact referent difficult.\n",
    "- **Text Summarization**\n",
    "    - The main aim of text summarization is to take a corpus of text documents—which could\n",
    "be a collection of texts, paragraphs, or sentences—and reducing the content appropriately\n",
    "to create a summary that retains the key points of the collection. Summarization can\n",
    "be carried out by looking at the various documents and trying to find out the keywords,\n",
    "phrases, and sentences that have an important prominence in the whole collection. Two\n",
    "main types of techniques for text summarization include extraction-based summarization\n",
    "and abstraction-based summarization . With the advent of huge amounts of text and\n",
    "unstructured data, the need for text summarization in getting to valuable insights quickly\n",
    "is in great demand.\n",
    "Text-summarization systems usually perform two main types of operations. The first\n",
    "is generic summarization , which tries to provide a generic summary of the collection of\n",
    "documents under analysis. The second type of operation is query-based summarization ,\n",
    "which provides query-relevant text summaries where the corpus is filtered further based\n",
    "on specific queries, relevant keywords and phrases are extracted relevant to the query,\n",
    "and the summary is constructed. Chapter 5 covers this in detail .\n",
    "- **Text Categorization**\n",
    "    - The main aim of text categorization is identifying to which category or class a specific\n",
    "document should be placed based on the contents of the document. This is one of the\n",
    "most popular applications of NLP and machine learning because with the right data, it\n",
    "is extremely simple to understand the principles behind its internals and implement a\n",
    "working text categorization system. Both supervised and unsupervised machine learning\n",
    "techniques can be used in solving this problem, and sometimes a combination of both is\n",
    "used. This has helped build a lot of successful and practical applications, including spam\n",
    "filters and news article categorization.\n",
    "- **Text Analytics**\n",
    "   - As mentioned before, with the advent of huge amounts of computing power, unstructured\n",
    "data, and success with machine learning and statistical analysis techniques, it wasn’t long\n",
    "before text analytics started garnering a lot of attention. However, text analytics poses\n",
    "some challenges compared to regular analytical methods. Free-flowing text is highly\n",
    "unstructured and rarely follows any specific pattern—like weather data or structured\n",
    "attributes in relational databases. Hence, standard statistical methods aren’t helpful when\n",
    "applied out of the box on unstructured text data. This section covers some of the main\n",
    "concepts in text analytics and also discusses the definition and scope of text analytics,\n",
    "which will give you a broad idea of what you can expect in the upcoming chapters.\n",
    "Text analytics , also known as text mining , is the methodology and process followed\n",
    "to derive quality and actionable information and insights from textual data. This involves\n",
    "using NLP, information retrieval, and machine learning techniques to parse unstructured\n",
    "text data into more structured forms and deriving patterns and insights from this data\n",
    "that would be helpful for the end user. Text analytics comprises a collection of machine\n",
    "learning, linguistic, and statistical techniques that are used to model and extract\n",
    "information from text primarily for analysis needs, including business intelligence,\n",
    "exploratory, descriptive, and predictive analysis. Here are some of the main techniques\n",
    "and operations in text analytics:.\n",
    "    - Text classification\n",
    "    - Text clustering\n",
    "    - Text summarization\n",
    "    - Sentiment analysis\n",
    "    - Entity extraction and recognition\n",
    "    - Similarity analysis and relation modeling\n",
    "    - Spam detection\n",
    "    - News articles categorization\n",
    "    - Social media analysis and monitoring\n",
    "    - Bio-medical\n",
    "    - Security intelligence\n",
    "    - Marketing and CRM\n",
    "    - Sentiment analysis\n",
    "    - Ad placements\n",
    "    - Chatbots\n",
    "    - Virtual assistants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
